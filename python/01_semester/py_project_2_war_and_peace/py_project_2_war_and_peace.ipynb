{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Project 2. Война и мир\n",
    "\n",
    "Текст произведения мы взяли в [библиотеке](http://az.lib.ru/t/tolstoj_lew_nikolaewich/text_0073.shtml) и провели первоначальную обработку. Поскольку наша цель — обработка слов из этого произведения, мы разбили текст на слова и вывели каждое слово в отдельной строке. Кроме того, в местах, где начинаются главы, мы вывели строку [new chapter]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка файла\n",
    "\n",
    "Напишем код, загружающий в память список слов текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    data = open('war_peace_processed.txt', 'rt').read().lower()\n",
    "    return data.split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишем эти данные в переменную:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подсчет слов\n",
    "\n",
    "Для начала посчитаем частоту использования отдельных слов в произведении. Для решения задачи воспользуемся уже знакомым нам словарём.\n",
    "\n",
    "Напишем функцию, считающую слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_target_word(data,target_word):\n",
    "    \n",
    "    frequency = data.count(target_word)\n",
    "\n",
    "    return frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для проверки работоспособности программы выведем, сколько раз слово \"князь\" будет найдено в тексте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1289"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_target_word(data,\"князь\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Подсчет Document Frequency\n",
    "\n",
    "*Document frequency* (для удобства сократим до *document_frequency*) — это доля документов, в которых встречается искомое слово. В нашем случае речь идёт не о документах, а о главах книги (выше мы писали, что в текстовом документе главы разделяются строкой ```[new chapter]```).\n",
    "\n",
    "Для начала напишем функцию, разделяющую главы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_chapters(data):\n",
    "    \n",
    "        lst = []\n",
    "        a = []\n",
    "        for j, i in enumerate(data):\n",
    "            if j + 1 == len(data):\n",
    "                lst.append(a.copy())\n",
    "                a.clear()\n",
    "            elif i != '[new chapter]':\n",
    "                a.append(i)\n",
    "            else:\n",
    "                lst.append(a.copy())\n",
    "                a.clear()\n",
    "                \n",
    "        return lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь напишем функцию, которая расчитывает *document frequency* для заданного слова ```target_word```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_frequency(data, target_word):\n",
    "    \n",
    "    lst = split_chapters(data)\n",
    "    \n",
    "    number_of_documents = 0\n",
    "    number_of_documents_with_target_word = 0\n",
    "    \n",
    "    for i in lst:\n",
    "        if target_word in i:\n",
    "            number_of_documents_with_target_word += 1\n",
    "        number_of_documents += 1\n",
    "        \n",
    "    document_frequency = number_of_documents_with_target_word / number_of_documents\n",
    "    \n",
    "    return document_frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем *document frequency* слова \"человек\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.672514619883041"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_frequency(data, \"человек\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Подсчет Term Frequency\n",
    "\n",
    "$\\textrm{term frequency(слово)} = \\dfrac{\\textrm{количество раз, когда слово встречается в тексте главы}}{\\textrm{количество всех слов в тексте главы}}$\n",
    "\n",
    "Попробуем посчитать частоту употребления слова *гостья* в $15$-й главе (кстати, у нас главы нумеруются с $0$). Слово гостья встречается в $15$-й главе $10$ раз, а общее количество слов — $1359$.\n",
    "\n",
    "Итого $\\textrm{term frequency(гостья)} \\approx 0.007$\n",
    "\n",
    "Напишем программу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_frequency(data, target_word, target_chapter):\n",
    "    lst = split_chapters(data)[target_chapter]\n",
    "    \n",
    "    frequency = lst.count(target_word)\n",
    "    term_frequency = frequency / len(lst)\n",
    "    \n",
    "    return term_frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем с помощью программы *term frequency* слова \"гостья\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007358351729212656"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_frequency(data, \"гостья\", 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подсчет контрастности слова\n",
    "\n",
    "Пришло время дать разъяснения: для чего мы делали вычисления выше и что нас ждет впереди?\n",
    "\n",
    "Если какое-то слово часто употребляется в документе, то, вероятно, этот документ что-то рассказывает о предмете/действии, описываемом этим словом. Скажем, если вы читаете книгу, в которой много раз употребляется слово *заяц*, то, вероятно, эта книга про зайцев.\n",
    "\n",
    "Однако, если вы возьмёте слово и, то оно будет встречаться почти в каждой книге много раз. Таким образом, если мы хотим найти наиболее значимые слова в книге, мы, с одной стороны, хотим найти наиболее частые слова, а с другой — убрать те, которые не несут важной информации, так как встречаются везде.\n",
    "\n",
    "Такая задача хорошо решается с помощью $\\textrm{tf*idf}$ — статистической метрики для оценки важности слова в тексте. Другими словами, $\\textrm{tf*idf}$ — это «контрастность» слова в документе (насколько оно выделяется среди других слов).\n",
    "\n",
    "$\\textrm{tf*idf} = \\textrm{term frequency} * \\textrm{inverse document frequency}$\n",
    "\n",
    "$\\textrm{tf}$ — это частотность термина, которая измеряет, насколько часто термин встречается в документе.\n",
    "\n",
    "$\\textrm{idf}$ — это обратная документная частотность термина. Она измеряет непосредственно важность термина во всём множестве документов.\n",
    "\n",
    "Мы будем использовать не сырые значения $\\textrm{tf}$ и $\\textrm{idf}$, а их логарифмы, то есть $\\log(1+\\textrm{tf}) * \\log{\\textrm{idf}}$.\n",
    "\n",
    "В качестве примера измерим $\\textrm{tf*idf}$ слова анна в главе $4$. Слово анна встречается в указанной главе $7$ раз ($\\textrm{tf}$), при этом в $4$ главе $1060$ слов (```chapter_size```), всего же слово анна упоминается в $32$ главах ($\\textrm{df}$) из $171$ (```chapter_count```).\n",
    "\n",
    "Таким образом $\\textrm{tf*idf}$ данного слова будет примерно равен $0.01$\n",
    "\n",
    "Напишем программу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(data, target_word, target_chapter):\n",
    "    from math import log\n",
    "    \n",
    "    log_tf = log(1 + term_frequency(data,target_word, target_chapter))\n",
    "    log_idf = log(1 / document_frequency(data, target_word))\n",
    "    \n",
    "    return  log_tf*log_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим работу программы на слове \"анна\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011031063403921838"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf(data, \"анна\", 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Топ 3 слов\n",
    "\n",
    "Теперь, когда мы умеем вычислять $\\textrm{tf*idf}$ для каждого слова в главе, мы можем найти те слова, которые являются самыми «контрастными» для данной главы, то есть они могут являться в своём роде заголовком для главы.\n",
    "\n",
    "Напишем программу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top3(data, target_chapter):\n",
    "    lst = split_chapters(data)\n",
    "    data_set = set(lst[target_chapter])\n",
    "    \n",
    "    top = [[i,tf_idf(data, i, target_chapter)] for i in data_set]\n",
    "    \n",
    "    top3 = sorted(top,key=lambda t:t[1])[:-4:-1]\n",
    "        \n",
    "    return top3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на топ 3 слова четвертой главы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['павловна', 0.014125754682156953],\n",
       " ['анна', 0.011031063403921838],\n",
       " ['прядильной', 0.00969211136471989]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top3(data, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом можно предположить, что речь в главе больше всех фигурирует Анна Павловна, и, если прочитать эту главу, то все действительно так."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итого\n",
    "\n",
    "По итогам этого проекта был получен опыт работы с такой статистической мерой, как $\\textrm{TF-IDF}$, которая позволяет сравнивать и исследовать тексты."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
