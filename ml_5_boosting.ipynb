{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ml_5_boosting.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNLmzlcEoxSZzuxQ35wRZvG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NeznaikanaLune/MISIS_DS_Masters_degree_2020/blob/master/ml_5_boosting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ondVYpwjBeHo"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from sklearn.preprocessing import PolynomialFeatures\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn import ensemble\r\n",
        "from sklearn import tree\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIedafAfBknV"
      },
      "source": [
        "# Бустинг. Практика"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QN01l7VuBjfV",
        "outputId": "8659f03a-a6b5-401b-bbf4-d9f96066d31a"
      },
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/vincentarelbundock/Rdatasets/master/csv/DAAG/spam7.csv',index_col=False)\r\n",
        "# Из столбца yesno сделайте столбец spam, где 1 соответствует значению y (является спамом), \r\n",
        "# а 0 – n (не является спамом). Удалите первый столбец (с индексом) и столбец \"yesno\".\r\n",
        "df['yesno'] = np.where(df['yesno']=='y',1,0)\r\n",
        "X = df.drop(['yesno','Unnamed: 0'],axis=1)\r\n",
        "Y = df['yesno']\r\n",
        "# Теперь мы хотим создать новые признаки путем попарного перемножения уже имеющихся друг на друга.\r\n",
        "memory = []\r\n",
        "l = list(X.columns)\r\n",
        "for i in X.columns:\r\n",
        "    l.remove(i)\r\n",
        "    for j in l:\r\n",
        "      X[i+'_'+j] = X[i]*X[j]\r\n",
        "    memory.append(i)\r\n",
        "\r\n",
        "# Разделим получившиеся данные на обучающую и тестовую выборки в соотношении 80:20.\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\r\n",
        "\r\n",
        "#Обучите модель GradientBoostingClassifier (из библиотеки sklearn), используя параметры \"по умолчанию\" \r\n",
        "#(на момент создания урока это learning_rate=0.1, n_estimators=100,max_depth=3, min_samples_split=2, min_samples_leaf=1, subsample=1, \r\n",
        "#max_features=None).\r\n",
        "#Во всех методах, где присутствует случайность, укажите random_state=42.\r\n",
        "#Это будет наш baseline. Укажите точность на тестовой выборке (параметр score), округлив до третьего знака после точки-разделителя.\r\n",
        "\r\n",
        "clf = ensemble.GradientBoostingClassifier(random_state=42)\r\n",
        "clf.fit(X_train, y_train)\r\n",
        "print(clf.score(X_test, y_test))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8653637350705755\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "3OuUuGAXGgMI",
        "outputId": "64364e03-9e1c-4fd2-f1c2-6e96617de0d0"
      },
      "source": [
        "#Воспользуйтесь методом feature_importances_. С его помощью можно оценить вклад каждого признака в обучение модели. \r\n",
        "#Постройте столбчатую диаграмму так, чтобы по горизонтали были указаны названия признаков, а по вертикали их важность. \r\n",
        "#В ответе укажите третий по важности признак (без кавычек и пробелов).\r\n",
        "feature_importances_frame = pd.DataFrame(list(X.columns),clf.feature_importances_).sort_index(ascending=False)\r\n",
        "print(feature_importances_frame.reset_index().iloc[2,1])\r\n",
        "feature_importances_frame.reset_index().set_index(0).iloc[:10].plot.barh();"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dollar_bang\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbYAAAD4CAYAAACALMPYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dfZxVZb338c9XRBEFVPT4UqmGjCJIGnXDMRSbyJ70pHYUsaMJ5i23JzWr29cdr4OpUSR6TI9HTcMiH04pYZooZXlC0OhWGRxgJB9TUqg0fECFgw/D7/5jX8h2nJm9h5n9wNrf9+s1r1nrWtd1rd81o/zmWmvtdSkiMDMzy4rtqh2AmZlZb3JiMzOzTHFiMzOzTHFiMzOzTHFiMzOzTNm+2gEY7LHHHtHQ0FDtMMzMtilLly5dGxF7ti93YqsBDQ0NNDc3VzsMM7NtiqQ/d1TuS5FmZpYpTmxmZpYpTmxmZpYpvsdmZrYNePPNN1m9ejUbN26sdigV169fP4YMGULfvn1Lqu/EVgNa16yjYep8AFbNPLLK0ZhZLVq9ejUDBgygoaEBSdUOp2IighdeeIHVq1czdOjQktr4UqSZ2TZg48aNDB48uK6SGoAkBg8e3K2ZqhObmdk2ot6S2mbdHXdNJjZJkyVd2UF5o6QjSmjfJGlseaJ7+xyrJO1RznOYmVn31dw9NkldxdQI5IBfFemmCXgN+EMvhWVmVlM235fvLaXc3x87dix/+EPp/6wuXLiQSy65hDvvvLMnoXVbVRKbpJOBc4AAVgBtwEbgAGBxKmvfZgdgOrCTpEOBC4G7gdnA+4ENwBTgFeB0oE3SScBZEXFfB/1dB/xPOuc/AF8GTgY+BjwQEZNTvauB0cBOwC0RcX67fnYCbk1fPwOuAD4C9AUuiIjbO/kZTEnx0mfgu94IY2ZWc7qT1Kqp4pciJY0EzgXGR8RHgbPToSHA2Ij4RkftIuIN4DxgTkQ0RsQc4NtAS0SMAv4NuCEiVgHXAJeleu9KagV2I5/Ivg7MAy4DRgL7S2pMdaZFRA4YBXxc0qiC9rsAdwA3RcS1wDRgQUSMAT4B/LuknTsZz6yIyEVErk//QV2EaGZWG3bZZRcgPxNramriuOOOY/jw4Zx44olEBAB33XUXw4cP58ADD+TWW299u+369ev58pe/zJgxYzjggAO4/fb83/xnn30206dPB+A3v/kNhx12GJs2bepRnNWYsY0H5kbEWoCIeDHdGJwbEW3d7OtQ4NjUzwJJgyUN7Eb7OyIiJLUCz0VEK4CklUADsAw4Ps2utgf2BkawZUZ5O3BxRPw07X8aOErSOWm/H/Be4JFujsvMrKa1tLSwcuVK9tlnHw455BAWL15MLpfjtNNOY8GCBXzgAx9g4sSJb9efMWMG48ePZ/bs2bz88suMGTOGww8/nAsvvJDRo0czbtw4vvrVr/KrX/2K7bbr2Zyrlh4eWV+Fc76evm8q2N68v72koeQvmX4yzQrnk09Wmy0GPqstj+wIODbNFBsj4r0R4aRmZpkzZswYhgwZwnbbbUdjYyOrVq3i0UcfZejQoQwbNgxJnHTSSW/X/+1vf8vMmTNpbGykqamJjRs38swzz9C/f3+uvfZaPvWpT3HmmWey33779Ti2aiS2BcAESYMBJO3ejbavAgMK9u8DTkz9NAFrI+KVDuptrYHkE+46SXsBn2t3/DzgJeCqtP8b4KzNiU7SAb0Qg5lZzdlxxx3f3u7Tpw9vvfVWl/Ujgl/84hcsW7aMZcuW8cwzz/DhD38YgNbWVgYPHsxf/vKXXomt4oktIlYCM4BFkpYDl3ZVX9JRkqan3XuAEZKWSZoIXAAcJGkFMBOYlOrdAXwh1RvXg1iXAy3Ao+QfDFncQbWzyT/QcjHwHfIPjaxIlzO/s7XnNjPb1gwfPpxVq1bxpz/9CYCbbrrp7WOf+cxnuOKKK96+F9fS0gLAn//8Z77//e/T0tLCr3/9ax544IEex1GVpyIj4nrg+i6OXwdcl7bnkX+wg4h4kfwTioWO6aD94+Qf9ugqhskF26vIP8nY0bHJdCAiGgp2TynY/t9dnbcj++87iGa/SsvMuqEWX7/Xr18/Zs2axZFHHkn//v0ZN24cr776KgDf+ta3+NrXvsaoUaPYtGkTQ4cO5Y477uDUU0/lkksuYZ999uHHP/4xkydPZsmSJfTr16/I2TqnzdnTqieXy4UXGjWzrjzyyCNvX7qrRx2NX9LS9NT6O9TcB7R7m6RpwIR2xXMjYkY14jEzs/LKfGJLCcxJzMysTtTS4/5mZtaFer111N1xO7GZmW0D+vXrxwsvvFB3yW3zemzdeZgk85cizcyyYMiQIaxevZq///3v1Q6l4javoF0qJzYzs21A3759S15But75UqSZmWWKE5uZmWWKE5uZmWWKE1sNaF2zjoap83t9RVwzs3rkxGZmZpnixGZmZplS0cQm6YKC1aU7On6dpOPS9kJJ73q5pZmZWVcyM2OT1KfaMZiZWfWVPbFJmibpcUm/Bz6Uyhol3S9phaTbJO1WpI+rJTVLWinp2wXlqyRdJOkh3v0G/811Fkq6LLV/RNJoSbdKekLSdwvqfUPSw+nra6msIbW5Np37t5J2Ssf2k3SXpKWS7pM0XNIASU9L6pvqDCzcbxfXlBRTc9uGdd3/wZqZWYfKmtgkHQScADQCR7BlkdAbgG9GxCigFTi/SFfT0po7o4CPSypcRPSFiDgwIm7uov0bqf01wO3AGeQXFp0saXCK8xTgH4GDgdMkHZDaDgOuioiRwMvAsal8FnBWRBwEnAP8ICJeBRYCm1cAPAG4NSLebB9QRMyKiFxE5Pr0H1Rk+GZmVqpyz9jGAbdFxIaIeIX8Stg7A7tGxKJU53rgsCL9HJ9mZS3ASGBEwbE5JcQxL31vBVZGxF8j4nXgKeA9wKEpzvUR8Rpwa4od4OmIWJa2lwINknYBxgJzJS0Dfgjsner8iC0rap8C/KSE+MzMrJfU/LsiJQ0lPyMaHREvSboOKHzN8/oSunk9fd9UsL15v9jPoLB+G7AT+T8IXo6IxvaVI2JxuoTZBPSJiIdLiM/MzHpJuWds9wLHSNpJ0gDg8+QT0UuSNs+IvgQs6qwDYGBqs07SXsDnyhDnfSnO/pJ2Br6QyjqUZp9PS5oAoLyPFlS5AfgZnq2ZmVVcWWdsEfGQpDnAcuB5YEk6NAm4RlJ/8pcDT+mkCyJiuaQW4FHgWWBxmeK8DngwFf0oIlokNXTR7ETgaknnAn2Bm8mPE+CnwHeBm0o5//77DqJ55pHFK5qZWVGqt0XrKiF9Fu/oiPhSKfVzuVw0NzeXOSozs2yRtDQ9GPgONX+PbVsj6Qryl0uPqHYsZmb1KDOJTdJVwCHtii+PiIre54qIsyp5PjMze6fMJLaIOKPaMZiZWfVl5pVaZmZm4MRmZmYZ48RmZmaZ4sRmZmaZ4sRmZmaZ4sRmZmaZkpnH/bdlrWvW0TB1/tv7q/x6LTOzreYZm5mZZYoTm5mZZUrNJTZJkyVd2UF5o6Si71+U1CRpbDfP+VqR4w2SHi7o/87u9G9mZpVTU4lNUlf3/Bop7cXCTeRXt64JRcZkZma9rOL/6Eo6mfyK2AGsIL8q9UbgAPJrra3ooM0OwHRgJ0mHAhcCdwOzgfcDG4ApwCvA6UCbpJOAsyLiXQuGplW5fwbsAtxeUC7gYvJv5w/guxExp4uxjAEuJ7+i9/8Ap0TEY5ImA/+c+u8DfLy0n46ZmfVURRObpJHAucDYiFgraXfgUmBIKmtLSeEdIuINSecBuYg4M/V1BdASEcdIGg/cEBGNkq4BXouIS7oI5XLg6oi4QVLhy5P/mfzM8KPAHsASSfd20c+jwLiIeEvS4cD3gGPTsQOBURHxYic/iynkkzF9Bu7ZxSnMzKw7Kn0pcjwwNyLWAhT8oz83Itq62dehwI2pnwXAYEkDS2x7CFtWt76xXZ83RURbRDwHLAJGd9HPIGBuuv92GTCy4NjdnSW1FPOsiMhFRK5P/0Elhm1mZsXUyj229VU4Z28sHf4d4J6I+AjwefKXJDerxpjMzOpepRPbAmCCpMEA6VJkqV4FBhTs3wecmPppAtZGxCsd1OvIYuCEtH1iuz4nSuojaU/gMODBLvoZBKxJ25OLD8HMzMqtooktIlYCM4BFkpaTv7/WKUlHSZqedu8BRkhaJmkicAFwkKQVwExgUqp3B/CFVG9cJ12fDZwhqRXYt6D8NvIPrywnn4T/b0T8rYsQLwYulNSC3+JiZlYTFNEbV+SsJ3K5XDQ3N1c7DDOzbYqkpRGRa19eK/fYzMzMekWmL59JmgZMaFc8NyJmVCMeMzMrv0wntpTAnMTMzOqIL0WamVmmOLGZmVmmOLGZmVmmOLGZmVmmOLGZmVmmOLGZmVmmOLGZmVmmZPpzbNuK1jXraJg6v1ttVs08skzRmJlt2zxjMzOzTHFi64Kk3SXdLemJ9H23VC5J/ynpSUkrJB1Y0GZSqv+EpEmd925mZuXgxNa1qcDvImIY8Lu0D/A5YFj6mgJcDW+vL3c+8I/AGOD8zcnQzMwqw4kNkNQg6RFJ10paKem3knYCjgauT9WuB45J20cDN0Te/cCukvYGPgPcHREvRsRLwN3AZys8HDOzuubEtsUw4KqIGAm8DBwL7BURf03H/wbslbb3BZ4taLs6lXVW/i6SpkhqltTctmFd743CzKzOObFt8XRELEvbS4GGwoORX5G111ZljYhZEZGLiFyf/oN6q1szs7rnxLbF6wXbbeQ/CvFcusRI+v58Or4GeE9B/SGprLNyMzOrECe2rs0DNj/ZOAm4vaD85PR05MHAunTJ8jfApyXtlh4a+XQqMzOzCvEHtLs2E/i5pFOBPwPHp/JfAUcATwIbgFMAIuJFSd8BlqR60yPixcqGbGZW35zYgIhYBXykYP+SgsOf7KB+AGd00tdsYHYvh2hmZiVyYqsB++87iGa/IsvMrFf4HpuZmWWKE5uZmWWKE5uZmWWKE5uZmWWKE5uZmWWKE5uZmWWKE5uZmWWKE5uZmWWKE5uZmWWKE5uZmWWKX6lVA1rXrKNh6vytarvKr+IyM3sHz9jMzCxTnNg6IWmypCs7KG+UdEQJ7ZskjS1PdGZm1hkntg5I6uoSbSP5tdiKaQKc2MzMKqxu77FJOhk4BwhgBdAGbAQOABansvZtdgCmAztJOhS4ELib/Ppr7ye/6OgU4BXgdKBN0knAWRFxX7nHZGZmdZrYJI0EzgXGRsRaSbsDlwJDUlmbpMnt20XEG5LOA3IRcWbq6wqgJSKOkTQeuCEiGiVdA7zWbtHSwhimkE+C9Bm4ZxlGaWZWn+r1UuR4YG5ErAWIiBdT+dyIaOtmX4cCN6Z+FgCDJQ0s1igiZkVELiJyffoP6uYpzcysM/Wa2DqzvtoBmJlZz9RrYlsATJA0GCBdiizVq8CAgv37gBNTP03A2oh4pYN6ZmZWAXWZ2CJiJTADWCRpOfn7a52SdJSk6Wn3HmCEpGWSJgIXAAdJWgHMBCalencAX0j1xpVjHGZm9m6KiGrHUPd23HtY7D3pP7aqrd88Ymb1StLSiMi1L6/LpyJrzf77DqLZCcrMrFfU5aVIMzPLLic2MzPLFCc2MzPLlKL32CQNB44G9k1Fa4B5EfFIOQMzMzPbGl3O2CR9E7gZEPBg+hJwk6Sp5Q/PzMyse4rN2E4FRkbEm4WFki4FVpL/3JaZmVnNKHaPbROwTwfle6djZmZmNaXYjO1rwO8kPQE8m8reC3wAOLOcgZmZmW2NLhNbRNwl6YPAGN758MiSrXgLvpmZWdkVfSoyIjYB91cgFjMzsx7zK7VqQOuadTRMnd+rffodkmZWr/wBbTMzyxQnNjMzy5SqJjZJkyVd2UF5o6QjSmjfJGlseaIzM7NtUdUSm6Su7u81AkUTG9AEOLGZmdnbyprYJJ0saYWk5ZJulHSdpGskPQBc3EmbHYDpwMTNq1RL2l3SL1Nf90saJakBOB34elerVKdzXp3aPZVmebMlPSLpuoJ6X5TUKulhSRcVlL8maUYaw/2S9krle0r6haQl6esQSdtJekLSnqnOdpKe3LzfLq4pkpolNbdtWLe1P2IzM2unbIlN0kjgXGB8RHwUODsdGgKMjYhvdNQuIt4AzgPmRERjRMwBvg20RMQo4N+AGyJiFXANcFmqd18X4ewGfAz4OjAPuAwYCeyfLnvuA1wEjCc/Wxwt6ZjUdmfg/jSGe4HTUvnl6dyjgWOBH6WPRvwXcGKqcziwPCL+3sE4Z0VELiJyffoP6iJ0MzPrjnI+7j8emBsRawEi4kVJpLLufrj7UPLJg4hYIGmwpIHdaH9HRISkVuC5iGgFkLQSaADeByzcnIAk/RQ4DPgl8AZwZ+pnKfCptH04MCKNCWCgpF2A2cDtwH8AXwZ+0s2xmplZD1Tjc2zrq3DO19P3TQXbm/e3B958V4st3oyISNttbPmZbQccHBEb29V/TdJzksaTf2PLiZiZWcWU8x7bAmCCpMEAknbvRttXgQEF+/eREoSkJmBtRLzSQb2t9SDwcUl7SOoDfBFYVKTNb4GzNu9Iaiw49iPylyS3ZnZqZmY9ULYZW0SslDQDWCSpDWjpqr6ko4BcRJwH3ANMlbQMuBC4AJgtaQWwAZiUmt0B3CLpaOCsIvfZuor1r2l9uXvIrzc3PyJuL9Lsq8BVKabtyd9/Oz0dm0f+EmRJlyH333cQzX5TiJlZr9CWq2zWWyTlyD9Y0uGTmu3lcrlobm4uc1RmZtkiaWlE5NqX+12RvSzN/P4V31szM6uKzCQ2SdOACe2K50bEjErGEREz8criZmZVk5nElhJYRZOYmZnVHr8E2czMMsWJzczMMsWJzczMMsWJzczMMsWJzczMMsWJzczMMiUzj/tvy1rXrKNh6vxe73eVX9NlZnXIMzYzM8sUJzYzM8sUJzZAUoOkh6sdh5mZ9ZwTm5mZZYoT2xbbS/qppEck3SKpv6TzJC2R9LCkWZIEIGmhpIskPSjpcUnjUnl/ST+X9EdJt0l6IC1hY2ZmFeLEtsWHgB9ExIeBV4CvAFdGxOiI+AiwE/BPBfW3j4gxwNeA81PZV4CXImIE8C3goM5OJmmKpGZJzW0b1pVhOGZm9cmJbYtnI2Jx2v4v4FDgE2nW1QqMB0YW1L81fV8KNKTtQ4GbASLiYWBFZyeLiFkRkYuIXJ/+g3pvFGZmdc6fY9ui/VLiAfwAyEXEs5IuAPoVHH89fW/DP0czs5rhGdsW75X0sbT9L8Dv0/ZaSbsAx5XQx2LgeABJI4D9ez1KMzPrkmcaWzwGnCFpNvBH4GpgN+Bh4G/AkhL6+AFwvaQ/Ao8CKwHfQDMzqyBFtL8CZ1tLUh+gb0RslLQf8N/AhyLija7a5XK5aG5urkiMZmZZIWlpRLzryXPP2HpXf+AeSX0BAV8pltTMzKx3ObH1ooh4FfDn1szMqsgPj5iZWaY4sZmZWaY4sZmZWaY4sZmZWaY4sZmZWaY4sZmZWaY4sZmZWaY4sZmZWab4A9o1oHXNOhqmzq/KuVfNPLIq5zUzKxfP2MzMLFOc2MzMLFNqLrFJukDSOV0cv07ScWl7oaQev5uxt/oxM7Pqq7nEVk5pWRkzM8uwmkhskqZJelzS74EPpbJGSfdLWiHpNkm7FenjaknNklZK+nZB+SpJF0l6CJjQRRdfkrRM0sOSxqS2YyT9P0ktkv4gaXNskyXdKukuSU9IurjgfKemsTwo6VpJV3YS75QUb3PbBq9FambWW6qe2CQdBJwANAJHAKPToRuAb0bEKKAVOL9IV9PSgnOjgI9LGlVw7IWIODAibu6iff+IaAS+AsxOZY8C4yLiAOA84HsF9RuBicD+wERJ75G0D/At4GDgEGB4ZyeLiFkRkYuIXJ/+g4oMzczMSlULj/uPA26LiA0AkuYBOwO7RsSiVOd6YG6Rfo6XNIX8mPYGRgAr0rE5JcRxE0BE3CtpoKRdgQHA9ZKGAQH0Laj/u4hYl2L+I/A+YA9gUUS8mMrnAh8s4dxmZtZLqj5j6w2ShgLnAJ9MM7z5QL+CKutL6CY62P8OcE9EfAT4fLs+Xy/YbqM2/kgwM6t7tZDY7gWOkbSTpAHkE8h64CVJ41KdLwGLOusAGJjarJO0F/C5rYhjIoCkQ4F1aTY2CFiTjk8uoY8l5C+D7iZpe+DYrYjDzMx6oOqzjIh4SNIcYDnwPPnkADAJuEZSf+Ap4JQu+lguqYX8PbFngcVbEcrG1Edf4Mup7GLylyLPJT8LLDaWNZK+BzwIvJji8ZMhZmYVpIj2V+CsJyTtEhGvpRnbbcDsiLitqza5XC6am5srE6CZWUZIWpoeGnyHWrgUmTUXSFoGPAw8DfyyyvGYmdWVql+KrCRJV5F/DL/Q5RHxk946R0R0+tYUMzMrv7pKbBFxRrVjMDOz8vKlSDMzyxQnNjMzyxQnNjMzyxQnNjMzyxQnNjMzyxQnNjMzyxQnNjMzy5S6+hxbrWpds46GqUVfRVnXVs08stohmNk2wjM2MzPLFCe2RNIFkjp9HZak6yQdl7YXSnrXizfNzKz6nNgqQFKfasdgZlYv6jqxSZom6XFJvwc+lMoaJd0vaYWk2yTtVqSPqyU1S1op6dsF5askXSTpIWBCeUdiZmab1W1ik3QQcALQCBwBjE6HbgC+GRGjgFbg/CJdTUvrAY0iv3r2qIJjL0TEgRFxcwfnn5ISYnPbBq9FambWW+o2sQHjgNsiYkNEvALMA3YGdo2IRanO9cBhRfo5Ps3KWoCRwIiCY3M6axQRsyIiFxG5Pv0HbfUgzMzsnfy4fw9IGgqcA4yOiJckXQf0K6iyviqBmZnVsXqesd0LHCNpJ0kDgM+TT0QvSRqX6nwJWNRZB8DA1GadpL2Az5UzYDMzK65uZ2wR8ZCkOcBy4HlgSTo0CbhGUn/gKeCULvpYLqkFeBR4Flhc3qjNzKyYuk1sABExA5jRwaGDO6g7uWC7qaPydvUbehqfmZl1X10ntlqx/76DaPYro8zMekU932MzM7MMcmIzM7NMcWIzM7NMcWIzM7NMcWIzM7NMcWIzM7NMcWIzM7NMcWIzM7NMcWIzM7NM8ZtHakDrmnU0TJ1f7TDMzCpqVZneuOQZm5mZZYoTm5mZZYoTm5mZZUrNJzZJkyVd2UF5o6QjSmjfJGlskTrXSTquJ3GamVltqOnEJqmrh1sagaKJDWgCukxsZmaWHVVPbJJOlrRC0nJJN6bZ0zWSHgAu7qTNDsB0YKKkZZImStpd0i9TX/dLGiWpATgd+HqqN66LUA6X1CzpcUn/lM7TIOk+SQ+lr7GpvEnSQkm3SHpU0k8lKR07IpUtlfSfku7sZAxT0vma2zas29ofn5mZtVPVx/0ljQTOBcZGxFpJuwOXAkNSWZukye3bRcQbks4DchFxZurrCqAlIo6RNB64ISIaJV0DvBYRlxQJpwEYA+wH3CPpA8DzwKciYqOkYcBNQC7VPwAYCfwFWAwcIqkZ+CFwWEQ8Lemmzk4WEbOAWQA77j0sisRmZmYlqvaMbTwwNyLWAkTEi6l8bkS0dbOvQ4EbUz8LgMGSBnaj/c8jYlNEPAE8BQwH+gLXSmoF5gIjCuo/GBGrI2ITsIx8YhwOPBURT6c6nSY2MzMrj1r9gPb6Kpyz/awpgK8DzwEfJf9HwMaC468XbLdRuz9LM7O6Uu0Z2wJggqTBAOlSZKleBQYU7N8HnJj6aQLWRsQrHdTrzARJ20naD3g/8BgwCPhrmpV9CehTpI/HgPene3sAE0saiZmZ9ZqqzjIiYqWkGcAiSW1AS1f1JR1F/r7aecA9wFRJy4ALgQuA2ZJWABuASanZHcAtko4GzoqI+zrp/hngQWAgcHq6r/YD4BeSTgbuoshMMiL+R9JXgLskrQeWFPkRALD/voNoLtOrZczM6o0i/NxCb5K0S0S8lp6SvAp4IiIu66pNLpeL5ubmygRoZpYRkpZGRK59ebUvRWbRaWkWuZL8pcwfVjkeM7O6UlcPPEiaBkxoVzw3Imb01jnS7KzLGZqZmZVPXSW2lMB6LYmZmVnt8aVIMzPLFD88UgMkvUr+owJZsQewttpB9JIsjQU8nlrn8XTP+yJiz/aFdXUpsoY91tGTPdsqSc1ZGU+WxgIeT63zeHqHL0WamVmmOLGZmVmmOLHVhlnVDqCXZWk8WRoLeDy1zuPpBX54xMzMMsUzNjMzyxQnNjMzyxQntgqR9FlJj0l6UtLUDo7vKGlOOv5AwdI3NamE8Rwm6SFJb0k6rhoxdkcJ4/mGpD9KWiHpd5LeV404S1XCeE6X1CppmaTfSxrRUT+1oth4CuodKykk1fQj8yX8fiZL+nv6/SyT9L+qEWepSvn9SDo+/T+0UtLPyhpQRPirzF/k13H7E/l13nYAlgMj2tX5CnBN2j4BmFPtuHs4ngZgFHADcFy1Y+6F8XwC6J+2/zUDv5+BBdtHAXdVO+6ejCfVGwDcC9xPfnmrqsfeg9/PZODKasfai+MZRn5Zst3S/j+UMybP2CpjDPBkRDwVEW8ANwNHt6tzNHB92r4F+GRa+qYWFR1PRKyKiBXApmoE2E2ljOeeiNiQdu8HhlQ4xu4oZTyvFOzuzLtXkK8lpfz/A/Ad4CLeudJ9LSp1PNuKUsZzGnBVRLwEEBHPlzMgJ7bK2Bd4tmB/dSrrsE5EvAWsAwZXJLruK2U825LujudU4NdljahnShqPpDMk/Qm4GPhqhWLbGkXHI+lA4D0RMb+SgW2lUv97OzZd+r5F0nsqE9pWKWU8HwQ+KGmxpPslfbacATmxmXWDpJOAHPDv1Y6lpyLiqojYD/gmcG6149lakrYDLgX+T7Vj6UV3AA0RMQq4my1Xc7ZV25O/HNkEfBG4VtKu5TqZE1tlrAEK/+Iakso6rCNpe/KLlL5Qkei6r5TxbEtKGo+kw4FpwFER8XqFYtsa3f393AwcU9aIeqbYeAYAHwEWSloFHAzMq+EHSIr+fiLihYL/xn4EHFSh2LZGKf+9rQbmRcSbEfE08Dj5RFcWTmyVsQQYJmmopB3IPxwyr12decCktH0csCDSXdYaVMp4tiVFxyPpABn1ueAAAAD4SURBVPKroR9V7vsDvaCU8RT+o3Ik8EQF4+uuLscTEesiYo+IaIiIBvL3QI+KiObqhFtUKb+fvQt2jwIeqWB83VXKvwe/JD9bQ9Ie5C9NPlW2iKr9RE29fAFHkP8r5U/AtFQ2nfz/gAD9gLnAk8CDwPurHXMPxzOa/F9p68nPPFdWO+Yejue/geeAZelrXrVj7uF4LgdWprHcA4ysdsw9GU+7ugup4aciS/z9XJh+P8vT72d4tWPu4XhE/nLxH4FW4IRyxuNXapmZWab4UqSZmWWKE5uZmWWKE5uZmWWKE5uZmWWKE5uZmWWKE5uZmWWKE5uZmWXK/wefANJ7dKfYOQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0m6lfMmzOPok",
        "outputId": "c5729ec1-38dc-43a2-89a9-4499eab4c848"
      },
      "source": [
        "#Теперь перейдем к подбору параметров в модели. Для этого в библиотеке scikit-learn есть метод GridSearchCV. \r\n",
        "#Ему на вход подается модель, список параметров и способ оценивания. \r\n",
        "#При запуске метода fit модель обучается со всеми возможными комбинациями параметров, \r\n",
        "#лучшей комбинацией параметров становится та, при которой значение метрики максимально.\r\n",
        "#Укажите в качестве estimator градиетный бустинг с параметрами \"по умолчанию\" и random_state=42. \r\n",
        "#В параметре scoring укажите 'accuracy', n_jobs=-1, cv=5.\r\n",
        "\r\n",
        "param_grid = {'learning_rate':[0.00001, 0.0001, 0.001, 0.01, 0.1, 1], \r\n",
        "              'n_estimators':[100, 250, 500, 750, 1000, 1250, 1500, 1750]}\r\n",
        "\r\n",
        "clf = ensemble.GradientBoostingClassifier(random_state=42)\r\n",
        "grid_search = GridSearchCV(clf, param_grid=param_grid, scoring='accuracy', cv=5)\r\n",
        "grid_search.fit(X_train, y_train)\r\n",
        "print(grid_search.score(X_test, y_test))\r\n",
        "print(grid_search.best_score_)\r\n",
        "print(grid_search.best_params_)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8610206297502715\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "km_XK4RZy7a3",
        "outputId": "8aa3e56e-607d-4134-9354-fb0ab8fd6d3f"
      },
      "source": [
        "grid_search.best_params_"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning_rate': 0.01, 'n_estimators': 1750}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBAhZK6nyta4",
        "outputId": "6eed92bc-3971-4ced-a7fd-de4d3d65ee45"
      },
      "source": [
        "# Теперь воспользуемся GridSearchCV для подбора максимальной глубины (max_depth). В качестве estimator используйте градиентный бустинг \r\n",
        "# с ранее подобранными параметрами и random_state=42. Переберите все значения max_depth от 5 до 15 включительно. \r\n",
        "# В ответ запишите значение параметра, при котором точность максимальна.\r\n",
        "\r\n",
        "param_grid = {'max_depth':range(5,16)}\r\n",
        "\r\n",
        "clf = ensemble.GradientBoostingClassifier(random_state=42,learning_rate= 0.01,n_estimators= 1750)\r\n",
        "grid_search = GridSearchCV(clf, param_grid=param_grid, scoring='accuracy', cv=5)\r\n",
        "grid_search.fit(X_train, y_train)\r\n",
        "print(grid_search.score(X_test, y_test))\r\n",
        "print(grid_search.best_score_)\r\n",
        "print(grid_search.best_params_)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8653637350705755\n",
            "0.8831521739130436\n",
            "{'max_depth': 5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-b6SKdqrJrY6"
      },
      "source": [
        "**Алгоритм построение AdaBoost:**\r\n",
        "\r\n",
        "1. Инициализируем веса объектов \r\n",
        "$w_j = \\frac{1}{N}, \\, j=1,2,\\dots,N$\r\n",
        "2. Для всех $i$ от 1 до T:\r\n",
        "\r\n",
        "  1) Строим классификатор $b_{i}(x)$ , используя веса $w_{i}$.\r\n",
        "\r\n",
        "  2) Вычисляем ошибку $err_i = \\frac{\\sum\\limits_{j=1}^{N}w_j[y_j \\neq b_i(x_j)]}{\\sum\\limits_{j=1}^{N}w_j}$\r\n",
        "\r\n",
        "  3) Вычисляем вес нового алгоритма $c_i = \\frac{1}{2} \\log{\\frac{1-err_i}{err_i}}$\r\n",
        "\r\n",
        "  4) Получаем новые веса объектов $w_j \\leftarrow w_j \\cdot exp\\left( c_i [y_j \\neq b_i(x_j)]\\right), \\, j = 1, \\dots, N.$\r\n",
        "\r\n",
        "  5) Нормируем веса объектов $w_j \\leftarrow \\frac{w_j}{\\sum\\limits_{j=1}^{N}w_j}.$\r\n",
        "\r\n",
        "3. Группируем полученные модели: $a_T(x) = sign\\left[\\sum\\limits_{i=1}^{T}c_i b_i(x)\\right]$    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Vkm6-EszJiO",
        "outputId": "3d8426a5-5782-478a-934a-76208209ac2b"
      },
      "source": [
        "# изучить код для реализации AdaBoost с нуля. Вам необходимо запустить эту функцию, но с дописанными строчками \r\n",
        "# (вычисление ошибки и веса алгоритма) на всех признаках, получившихся после всех преобразований в предыдущем датасете \r\n",
        "#(до разделения выборки на обучающую и тестовую). Параметр learning_rate возьмите равным 0.001, М = 10. \r\n",
        "# В ответ запишите точность, округленную до трёх знаков после точки-разделителя.\r\n",
        "\r\n",
        "\r\n",
        "def AdaBoost_scratch(X,y, M=10, learning_rate =1):\r\n",
        "\t# инициалиазция служебных переменных\r\n",
        "\tN = len(y)\r\n",
        "\testimator_list, y_predict_list, estimator_error_list, estimator_weight_list, sample_weight_list = [], [],[],[],[]\r\n",
        "\t\r\n",
        "\t# инициализация весов\r\n",
        "\tsample_weight = np.ones(N) / N\r\n",
        "\tsample_weight_list.append(sample_weight.copy())\r\n",
        "\t\r\n",
        "\t# цикл по длине М\r\n",
        "\tfor m in range(M):\r\n",
        "\r\n",
        "\t\t# обучим базовую модель и получим предсказание\r\n",
        "\t\testimator = tree.DecisionTreeClassifier(max_depth = 1, max_leaf_nodes=2)\r\n",
        "\t\testimator.fit(X, y, sample_weight=sample_weight)\r\n",
        "\t\ty_predict = estimator.predict(X)\r\n",
        "\t\t\r\n",
        "\t\t# Маска для ошибок классификации\r\n",
        "\t\tincorrect = (y_predict != y)\r\n",
        "\t\t\r\n",
        "\t\t# Оцениваем ошибку\r\n",
        "\t\testimator_error = sum(sample_weight*incorrect)/sum(sample_weight)\r\n",
        "\t\t# Вычисляем вес нового алгоритма\r\n",
        "\t\testimator_weight =  0.5*np.log((1-estimator_error)/estimator_error)\r\n",
        "\t  \r\n",
        "\t\tsample_weight *= np.exp(estimator_weight * incorrect * ((sample_weight > 0) | (estimator_weight < 0)))/sum(sample_weight)\r\n",
        "\r\n",
        "\t\t# Сохраяем результаты данной итерации\r\n",
        "\t\testimator_list.append(estimator)\r\n",
        "\t\ty_predict_list.append(y_predict.copy())\r\n",
        "\t\testimator_error_list.append(estimator_error)\r\n",
        "\t\testimator_weight_list.append(estimator_weight.copy())\r\n",
        "\t\tsample_weight_list.append(sample_weight.copy())\r\n",
        "\r\n",
        "\t# Для удобства переведем в numpy.array\r\n",
        "\testimator_list = np.asarray(estimator_list)\r\n",
        "\ty_predict_list = np.asarray(y_predict_list)\r\n",
        "\testimator_error_list = np.asarray(estimator_error_list)\r\n",
        "\testimator_weight_list = np.asarray(estimator_weight_list)\r\n",
        "\tsample_weight_list = np.asarray(sample_weight_list)\r\n",
        "\r\n",
        "\t# Получим предсказания\r\n",
        "\t\r\n",
        "\tpreds = (np.array([np.sign((y_predict_list[:,point] * estimator_weight_list).sum()) for point in range(N)]))\r\n",
        "\tprint('Accuracy = ', accuracy_score(preds, y))\r\n",
        "\r\n",
        "\treturn estimator_list, estimator_weight_list, sample_weight_list\r\n",
        "\r\n",
        "Y = Y.replace({0:-1})\r\n",
        "estimator_list, estimator_weight_list, sample_weight_list = AdaBoost_scratch(X, Y, M=10, learning_rate=0.001)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy =  0.8641599652249511\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pltZQoi3_YuY",
        "outputId": "51b9b6f4-bf3c-491c-a2b3-bab62a83b49d"
      },
      "source": [
        "# изучить код для реализации AdaBoost с нуля. Вам необходимо запустить эту функцию, но с дописанными строчками \r\n",
        "# (вычисление ошибки и веса алгоритма) на всех признаках, получившихся после всех преобразований в предыдущем датасете \r\n",
        "#(до разделения выборки на обучающую и тестовую). Параметр learning_rate возьмите равным 0.001, М = 10. \r\n",
        "# В ответ запишите точность, округленную до трёх знаков после точки-разделителя.\r\n",
        "\r\n",
        "Y = Y.replace({0:-1})\r\n",
        "M=10\r\n",
        "learning_rate =1\r\n",
        "\t# инициалиазция служебных переменных\r\n",
        "N = len(Y)\r\n",
        "estimator_list, y_predict_list, estimator_error_list, estimator_weight_list, sample_weight_list = [], [],[],[],[]\r\n",
        "\t\r\n",
        "# инициализация весов\r\n",
        "sample_weight = np.ones(N) / N\r\n",
        "sample_weight_list.append(sample_weight.copy())\r\n",
        "\t\r\n",
        "\t# цикл по длине М\r\n",
        "for m in range(M):\r\n",
        "\r\n",
        "\t\t# обучим базовую модель и получим предсказание\r\n",
        "\t\testimator = tree.DecisionTreeClassifier(max_depth = 1, max_leaf_nodes=2)\r\n",
        "\t\testimator.fit(X, Y, sample_weight=sample_weight)\r\n",
        "\t\ty_predict = estimator.predict(X)\r\n",
        "\t\t\r\n",
        "\t\t# Маска для ошибок классификации\r\n",
        "\t\tincorrect = (y_predict != Y)\r\n",
        "\t\t# print(incorrect)\r\n",
        "\t\t# Оцениваем ошибку\r\n",
        "\t\testimator_error = sum(sample_weight*incorrect)/sum(sample_weight)\r\n",
        "\t\t# Вычисляем вес нового алгоритма\r\n",
        "\t\testimator_weight =  0.5*np.log((1-estimator_error)/estimator_error)\r\n",
        "\t\tprint(type((sample_weight > 0) | (estimator_weight < 0)))\r\n",
        "\t\t# print(incorrect )\r\n",
        "\t\tsample_weight *= np.exp(estimator_weight * incorrect )/sum(sample_weight) # новые веса или меняются с домножением на вес модели, или остаются прежними в зависимости от маски\r\n",
        "\r\n",
        "\t\t# Сохраяем результаты данной итерации\r\n",
        "\t\testimator_list.append(estimator)\r\n",
        "\t\ty_predict_list.append(y_predict.copy())\r\n",
        "\t\testimator_error_list.append(estimator_error)\r\n",
        "\t\testimator_weight_list.append(estimator_weight.copy())\r\n",
        "\t\tsample_weight_list.append(sample_weight.copy())\r\n",
        "\r\n",
        "# Для удобства переведем в numpy.array\r\n",
        "estimator_list = np.asarray(estimator_list)\r\n",
        "y_predict_list = np.asarray(y_predict_list)\r\n",
        "estimator_error_list = np.asarray(estimator_error_list)\r\n",
        "estimator_weight_list = np.asarray(estimator_weight_list)\r\n",
        "sample_weight_list = np.asarray(sample_weight_list)\r\n",
        "\r\n",
        "\t# Получим предсказания\r\n",
        "\t\r\n",
        "preds = (np.array([np.sign((y_predict_list[:,point] * estimator_weight_list).sum()) for point in range(N)]))\r\n",
        "print('Accuracy = ', accuracy_score(preds, Y))\r\n"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'pandas.core.series.Series'>\n",
            "<class 'pandas.core.series.Series'>\n",
            "<class 'pandas.core.series.Series'>\n",
            "<class 'pandas.core.series.Series'>\n",
            "<class 'pandas.core.series.Series'>\n",
            "<class 'pandas.core.series.Series'>\n",
            "<class 'pandas.core.series.Series'>\n",
            "<class 'pandas.core.series.Series'>\n",
            "<class 'pandas.core.series.Series'>\n",
            "Accuracy =  0.8641599652249511\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQNBjpakDc1q",
        "outputId": "9fba47d3-477e-4ae0-e6b7-e1d345540903"
      },
      "source": [
        "np.exp(pd.Series([False,False,False,False])*pd.Series([1,2,3,4]))"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1.0\n",
              "1    1.0\n",
              "2    1.0\n",
              "3    1.0\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlYP_dWNwaev"
      },
      "source": [
        "# *Практика*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmecdeR9FdzM"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from sklearn.model_selection import train_test_split, KFold\r\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\r\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\r\n",
        "from sklearn.base import clone\r\n",
        "\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from tqdm import tqdm\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "\r\n",
        "%matplotlib inline"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnwvV8XWHbpd"
      },
      "source": [
        "def compute_meta_feature(clf, X_train, X_test, y_train, cv):\r\n",
        "    \r\n",
        "    X_meta_train = np.zeros_like(y_train, dtype=np.float32)\r\n",
        "    for train_fold_index, predict_fold_index in cv.split(X_train):\r\n",
        "        X_fold_train, X_fold_predict = X_train[train_fold_index], X_train[predict_fold_index]\r\n",
        "        y_fold_train = y_train[train_fold_index]\r\n",
        "        \r\n",
        "        folded_clf = clone(clf)\r\n",
        "        folded_clf.fit(X_fold_train, y_fold_train)\r\n",
        "        X_meta_train[predict_fold_index] = folded_clf.predict_proba(X_fold_predict)[:, 1]\r\n",
        "    print(len(X_meta_train))\r\n",
        "    meta_clf = clone(clf)\r\n",
        "    meta_clf.fit(X_train, y_train)\r\n",
        "    \r\n",
        "    X_meta_test = meta_clf.predict_proba(X_test)[:, 1]\r\n",
        "    \r\n",
        "    return X_meta_train, X_meta_test\r\n",
        "\r\n",
        "def generate_meta_features(classifiers, X_train, X_test, y_train, cv):\r\n",
        "   \r\n",
        "    features = [\r\n",
        "        compute_meta_feature(clf, X_train, X_test, y_train, cv)\r\n",
        "        for clf in tqdm(classifiers)\r\n",
        "    ]\r\n",
        "    \r\n",
        "    stacked_features_train = np.vstack([\r\n",
        "        features_train for features_train, features_test in features\r\n",
        "    ]).T\r\n",
        "\r\n",
        "    stacked_features_test = np.vstack([\r\n",
        "        features_test for features_train, features_test in features\r\n",
        "    ]).T\r\n",
        "    \r\n",
        "    return stacked_features_train, stacked_features_test"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "JIA5GC_3rN5C",
        "outputId": "7deb8523-e301-4c06-92b0-d4d060c0c1f1"
      },
      "source": [
        "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.data.gz', sep=',', header=None)[:10000]\r\n",
        "print(df.shape)\r\n",
        "features = list(range(0, 54))\r\n",
        "target = 54\r\n",
        "\r\n",
        "df = df[(df[target] == 1) | (df[target] == 2)]\r\n",
        "cover_train, cover_test = train_test_split(df, test_size=0.5)\r\n",
        "\r\n",
        "cover_X_train, cover_y_train = cover_train[features], cover_train[target]\r\n",
        "cover_X_test, cover_y_test = cover_test[features], cover_test[target]\r\n",
        "scaler = StandardScaler()\r\n",
        "cover_X_train = scaler.fit_transform(cover_X_train)\r\n",
        "cover_X_test = scaler.transform(cover_X_test)\r\n",
        "df.head(3)\r\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 55)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2804</td>\n",
              "      <td>139</td>\n",
              "      <td>9</td>\n",
              "      <td>268</td>\n",
              "      <td>65</td>\n",
              "      <td>3180</td>\n",
              "      <td>234</td>\n",
              "      <td>238</td>\n",
              "      <td>135</td>\n",
              "      <td>6121</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2785</td>\n",
              "      <td>155</td>\n",
              "      <td>18</td>\n",
              "      <td>242</td>\n",
              "      <td>118</td>\n",
              "      <td>3090</td>\n",
              "      <td>238</td>\n",
              "      <td>238</td>\n",
              "      <td>122</td>\n",
              "      <td>6211</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2579</td>\n",
              "      <td>132</td>\n",
              "      <td>6</td>\n",
              "      <td>300</td>\n",
              "      <td>-15</td>\n",
              "      <td>67</td>\n",
              "      <td>230</td>\n",
              "      <td>237</td>\n",
              "      <td>140</td>\n",
              "      <td>6031</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1   2    3    4     5    6    7   ...  47  48  49  50  51  52  53  54\n",
              "2  2804  139   9  268   65  3180  234  238  ...   0   0   0   0   0   0   0   2\n",
              "3  2785  155  18  242  118  3090  238  238  ...   0   0   0   0   0   0   0   2\n",
              "5  2579  132   6  300  -15    67  230  237  ...   0   0   0   0   0   0   0   2\n",
              "\n",
              "[3 rows x 55 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enFCS4xUr9Mu"
      },
      "source": [
        "Stacking — еще один способ объединить несколько алгоритмов в один, который часто используется как в решении реальных задач из промышленной сферы, так и в конкурсах на платформах вроде Kaggle.\r\n",
        "Подход использует понятие _базовых классификаторов_, каждый из которых независимо обучается на некотором (возможно одном и том же) множестве признаков, а также _мета-классификатора_, использующего предсказания базовых классификаторов как признаки.\r\n",
        "\r\n",
        "Для избежания переобучения будем разбивать обучающую выборку на фолды.\r\n",
        "Например, фолды при разбиении на три части:\r\n",
        "==*\r\n",
        "=*=\r\n",
        "*==\r\n",
        "\r\n",
        "Это требуется для того, чтобы получить новые признаки (ответы алгоритмов на первом уровне) на всей обучающей выборке, т.е. ответы алгоритма на тех объектах, которые не были использованы во время обучения. В примере выше мы будем использовать ответы алгоритма, полученные на объектах звездочках. _Важно_: на каждом фолде мы обучаем алгоритм заново."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCblYzvyrXWD",
        "outputId": "babf07b3-5d9e-4511-c0e6-110b75eec5aa"
      },
      "source": [
        "np.random.seed(42)\r\n",
        "\r\n",
        "clf = GradientBoostingClassifier(n_estimators=300)\r\n",
        "clf.fit(cover_X_train, cover_y_train)\r\n",
        "\r\n",
        "accuracy_score(clf.predict(cover_X_test), cover_y_test)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7730796335447498"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgz35fbSsG4P",
        "outputId": "37eb35e6-5d9d-4029-a89b-97b1d09d6a62"
      },
      "source": [
        "cv = KFold(n_splits=10, shuffle=True)\r\n",
        "\r\n",
        "stacked_features_train, stacked_features_test = generate_meta_features([\r\n",
        "    LogisticRegression(C=0.001, penalty='l1', solver='liblinear', max_iter=5000),\r\n",
        "    LogisticRegression(C=0.001, penalty='l2', solver='liblinear', max_iter=5000),  \r\n",
        "    RandomForestClassifier(n_estimators=300, n_jobs=-1),\r\n",
        "    GradientBoostingClassifier(n_estimators=300)\r\n",
        "], cover_X_train, cover_X_test, cover_y_train.values, cv)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/4 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1418\n",
            "1418\n",
            "1418\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 75%|███████▌  | 3/4 [00:11<00:03,  3.81s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1418\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:25<00:00,  6.28s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0W9McCAsbOH",
        "outputId": "4541df6f-947a-42d5-870e-a02d6c19abbe"
      },
      "source": [
        "total_features_train = np.hstack([cover_X_train, stacked_features_train])\r\n",
        "total_features_test = np.hstack([cover_X_test, stacked_features_test])\r\n",
        "np.random.seed(42)\r\n",
        "clf = LogisticRegression(penalty='none', solver='lbfgs')\r\n",
        "clf.fit(stacked_features_train, cover_y_train)\r\n",
        "accuracy_score(clf.predict(stacked_features_test), cover_y_test)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7942212825933757"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNRC7v8mwjQ6"
      },
      "source": [
        "# Задача"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxx5FNkvscll"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "from sklearn.ensemble import (AdaBoostClassifier, GradientBoostingClassifier,\r\n",
        "                              RandomForestClassifier, ExtraTreesClassifier)\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.base import clone\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "from sklearn.datasets import load_digits\r\n",
        "\r\n",
        "from tqdm import tqdm\r\n",
        "\r\n",
        "from sklearn.model_selection import RandomizedSearchCV\r\n",
        "from scipy.stats.distributions import randint"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbVyjjhnwoGY"
      },
      "source": [
        "dataset = load_digits()\r\n",
        "X, y = dataset['data'], dataset['target']\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qqy-ySD8xGyM"
      },
      "source": [
        "Мы разобрали схему генерации признаков в стекинге, когда для тестовой выборки алгоритм заново переобучался на всей тренировочной выборке. Реализуйте схему, когда вместо этого производится агрегация ответов всех обученных на фолдах классификаторов на тестовой выборке при помощи усреднения.\r\n",
        "\r\n",
        "Логика решения:\r\n",
        "\r\n",
        "1) Создадим X_meta_test, заполним его нулями (по аналогии с X_meta_train);\r\n",
        "\r\n",
        "2) Далее на каждом шаге, где мы обучаем folded_clf.fit (X_fold_train, y_fold_train) и его предсказания на X_fold_predict запихиваем в X_meta_train[predict_fold_index] добавим еще одну строку, где в X_meta_test будем добавлять предсказания вероятностей folded_clf на X_test. Их можно сразу складывать друг с другом или сохранить много массивов, тогда в конце их нужно будет все сложить, а потом делить на количество сплитов (количество массивов равно количеству сплитов в кросс - валидации);\r\n",
        "\r\n",
        "3) После цикла останется только усреднить все эти массивы, это и будет наш X_meta_test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QuhEKMewrte"
      },
      "source": [
        "def compute_meta_feature(clf, X_train, X_test, y_train, cv):\r\n",
        "    \"\"\"    Эта функция подсчитывает признаки для мета-классификатора.     \r\n",
        "    Они являются вероятностями классов при решении задачи многоклассовой классификации.    \r\n",
        "    :arg clf: классификатор    \r\n",
        "    :args X_train, y_train: обучающая выборка    \r\n",
        "    :arg X_test: признаки тестовой выборки    \r\n",
        "    :arg cv: класс, генерирующий фолды (KFold)    \r\n",
        "    :returns X_meta_train, X_meta_test: новые признаки для обучающей и тестовой выборок    \"\"\"\r\n",
        "\r\n",
        "    n_classes = len(np.unique(y_train))\r\n",
        "    X_meta_train = np.zeros((len(X_train), n_classes), dtype=np.float32)\r\n",
        "    X_meta_test = np.zeros((len(X_test), n_classes), dtype=np.float32)\r\n",
        "    for train_fold_index, predict_fold_index in cv.split(X_train):\r\n",
        "        X_fold_train, X_fold_predict = X_train[train_fold_index], X_train[predict_fold_index]\r\n",
        "        y_fold_train = y_train[train_fold_index]\r\n",
        "\r\n",
        "        folded_clf = clone(clf)\r\n",
        "        folded_clf.fit(X_fold_train, y_fold_train)\r\n",
        "\r\n",
        "        X_meta_train[predict_fold_index] = folded_clf.predict_proba(X_fold_predict)\r\n",
        "        X_meta_test+= folded_clf.predict_proba(X_test)\r\n",
        "    X_meta_test = X_meta_test/cv.n_splits\r\n",
        "\r\n",
        "    return X_meta_train, X_meta_test\r\n",
        "\r\n",
        "stacked_features_train, stacked_features_test = compute_meta_feature(GradientBoostingClassifier(n_estimators=300), cover_X_train, cover_X_test, cover_y_train.values, cv)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zvl0s4Nk844X"
      },
      "source": [
        "Используйте функцию generate_meta_features для стекинга следующих алгоритмов:\r\n",
        "логистическая регрессия с L1-регуляризацией, C=0.001, солвер — 'saga', схема работы мультиклассовой классификации — one-vs-rest, максимальное допустимое количество итераций — 2000\r\n",
        "логистическая регрессия с L2-регуляризацией, C=0.001, солвер — 'saga', схема работы мультиклассовой классификации — multinomial, максимальное допустимое количество итераций — 2000\r\n",
        "случайный лес из 300 деревьев\r\n",
        "градиентный бустинг из 200 деревьев\r\n",
        "Как мета-алгоритм используйте логистическую регрессию без регуляризации со схемой работы мультиклассовой классификации — auto и солвером 'lbfgs'.\r\n",
        "Посчитайте качество при помощи передачи новых признаков в функцию compute_metric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yefElvkM8R4T",
        "outputId": "8af22fd3-e196-4653-9189-0c1518393a84"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "from sklearn.ensemble import (AdaBoostClassifier, GradientBoostingClassifier,\r\n",
        "                              RandomForestClassifier, ExtraTreesClassifier)\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.base import clone\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "from sklearn.datasets import load_digits\r\n",
        "\r\n",
        "from tqdm import tqdm\r\n",
        "\r\n",
        "from sklearn.model_selection import RandomizedSearchCV\r\n",
        "from scipy.stats.distributions import randint\r\n",
        "\r\n",
        "dataset = load_digits()\r\n",
        "X, y = dataset['data'], dataset['target']\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\r\n",
        "\r\n",
        "def compute_meta_feature(clf, X_train, X_test, y_train, cv):\r\n",
        "    \r\n",
        "    n_classes = len(np.unique(y_train))\r\n",
        "    X_meta_train = np.zeros((len(y_train), n_classes), dtype=np.float32)\r\n",
        "\r\n",
        "    splits = cv.split(X_train)\r\n",
        "    for train_fold_index, predict_fold_index in splits:\r\n",
        "        X_fold_train, X_fold_predict = X_train[train_fold_index], X_train[predict_fold_index]\r\n",
        "        y_fold_train = y_train[train_fold_index]\r\n",
        "        \r\n",
        "        folded_clf = clone(clf)\r\n",
        "        folded_clf.fit(X_fold_train, y_fold_train)\r\n",
        "        \r\n",
        "        X_meta_train[predict_fold_index] = folded_clf.predict_proba(X_fold_predict)\r\n",
        "    \r\n",
        "    meta_clf = clone(clf)\r\n",
        "    meta_clf.fit(X_train, y_train)\r\n",
        "    \r\n",
        "    X_meta_test = meta_clf.predict_proba(X_test)\r\n",
        "    \r\n",
        "    return X_meta_train, X_meta_test\r\n",
        "\r\n",
        "def generate_meta_features(classifiers, X_train, X_test, y_train, cv):\r\n",
        "   \r\n",
        "    features = [\r\n",
        "        compute_meta_feature(clf, X_train, X_test, y_train, cv)\r\n",
        "        for clf in tqdm(classifiers)\r\n",
        "    ]\r\n",
        "    \r\n",
        "    stacked_features_train = np.hstack([\r\n",
        "        features_train for features_train, features_test in features\r\n",
        "    ])\r\n",
        "\r\n",
        "    stacked_features_test = np.hstack([\r\n",
        "        features_test for features_train, features_test in features\r\n",
        "    ])\r\n",
        "    \r\n",
        "    return stacked_features_train, stacked_features_test\r\n",
        "\r\n",
        "cv = KFold(n_splits=10, shuffle=True, random_state=42)\r\n",
        "\r\n",
        "def compute_metric(clf, X_train=X_train, y_train=y_train, X_test=X_test,y_test=y_test):\r\n",
        "    clf.fit(X_train, y_train)\r\n",
        "    y_test_pred = clf.predict(X_test)\r\n",
        "    return np.round(f1_score(y_test, y_test_pred, average='macro'), 6)\r\n",
        "\r\n",
        "stacked_features_train, stacked_features_test = generate_meta_features([\r\n",
        "    LogisticRegression(C=0.001, penalty='l1', solver='saga', max_iter=2000,multi_class='ovr',random_state=42),\r\n",
        "    LogisticRegression(C=0.001, penalty='l2', solver='saga', max_iter=2000,multi_class='multinomial',random_state=42),  \r\n",
        "    RandomForestClassifier(n_estimators=300, n_jobs=-1,random_state=42),\r\n",
        "    GradientBoostingClassifier(n_estimators=200,random_state=42)\r\n",
        "], X_train, X_test, y_train, cv)\r\n",
        "\r\n",
        "np.random.seed(42)\r\n",
        "clf = LogisticRegression(penalty='none', solver='lbfgs',multi_class='auto',random_state=42)\r\n",
        "clf.fit(stacked_features_train, y_train)\r\n",
        "accuracy_score(clf.predict(stacked_features_test), y_test)\r\n",
        "\r\n",
        "compute_metric(clf, X_train=stacked_features_train, y_train=y_train, X_test=stacked_features_test,y_test=y_test)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 1/4 [00:42<02:07, 42.47s/it]\u001b[A\n",
            " 50%|█████     | 2/4 [00:43<01:00, 30.16s/it]\u001b[A\n",
            " 75%|███████▌  | 3/4 [00:55<00:24, 24.57s/it]\u001b[A\n",
            "100%|██████████| 4/4 [02:28<00:00, 37.24s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.975579"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1O803mcCIUWI"
      },
      "source": [
        "При запуске в Juputer Notebook Windows10 PC f1= 0.978096. Именно этот ответ проходит грейдер на 15.12.2020\r\n",
        "![image.png](data:image/png;base64,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)\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNCzd97pHx3l"
      },
      "source": [
        "Используйте функцию generate_meta_features для стекинга следующих алгоритмов:\r\n",
        "\r\n",
        "- случайный лес из 300 деревьев\r\n",
        "- случайный лес из 200 экстремальных деревьев\r\n",
        "\r\n",
        "Как мета-алгоритм используйте логистическую регрессию без регуляризации со схемой работы мультиклассовой классификации — auto и солвером 'lbfgs'.\r\n",
        "Посчитайте качество при помощи передачи новых признаков в функцию compute_metric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1msOrf3y-CRe",
        "outputId": "9a2b8e6f-bd8c-4605-cc7c-0ffc045922e9"
      },
      "source": [
        "stacked_features_train, stacked_features_test = generate_meta_features([\r\n",
        "    RandomForestClassifier(n_estimators=200, n_jobs=-1,random_state=42),\r\n",
        "    ExtraTreesClassifier(n_estimators=300, n_jobs=-1,random_state=42)\r\n",
        "], X_train, X_test, y_train, cv)\r\n",
        "\r\n",
        "np.random.seed(42)\r\n",
        "clf = LogisticRegression(penalty='none', solver='lbfgs',multi_class='auto',random_state=42)\r\n",
        "clf.fit(stacked_features_train, y_train)\r\n",
        "accuracy_score(clf.predict(stacked_features_test), y_test)\r\n",
        "\r\n",
        "compute_metric(clf, X_train=stacked_features_train, y_train=y_train, X_test=stacked_features_test,y_test=y_test)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:08<00:08,  8.60s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:17<00:00,  8.77s/it]\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.984526"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1igvYc2uKMvt"
      },
      "source": [
        "Используйте функцию generate_meta_features для стекинга следующих алгоритмов:\r\n",
        "- метод ближайшего соседа (k-NN) со стандартными параметрами\r\n",
        "- случайный лес из 300 экстремальных деревьев\r\n",
        "\r\n",
        "Как мета-алгоритм используйте логистическую регрессию без регуляризации со схемой работы мультиклассовой классификации — auto и солвером 'lbfgs'.\r\n",
        "Посчитайте качество при помощи передачи новых признаков в функцию compute_metric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mAEdQFDICO0",
        "outputId": "1a13832c-e172-4866-b9d2-a2741edceb3e"
      },
      "source": [
        "stacked_features_train, stacked_features_test = generate_meta_features([\r\n",
        "    KNeighborsClassifier(),\r\n",
        "    ExtraTreesClassifier(n_estimators=300, n_jobs=-1,random_state=42)\r\n",
        "], X_train, X_test, y_train, cv)\r\n",
        "\r\n",
        "np.random.seed(42)\r\n",
        "clf = LogisticRegression(penalty='none', solver='lbfgs',multi_class='auto',random_state=42)\r\n",
        "clf.fit(stacked_features_train, y_train)\r\n",
        "accuracy_score(clf.predict(stacked_features_test), y_test)\r\n",
        "\r\n",
        "compute_metric(clf, X_train=stacked_features_train, y_train=y_train, X_test=stacked_features_test,y_test=y_test)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:00<00:00,  2.59it/s]\u001b[A\n",
            "100%|██████████| 2/2 [00:09<00:00,  4.67s/it]\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.989904"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9cQ0wcsK0-a"
      },
      "source": [
        "Используйте функцию generate_meta_features для стекинга следующих алгоритмов:\r\n",
        "-логистическая регрессия с L1-регуляризацией, C=0.001, солвер — 'saga', схема работы мультиклассовой классификации — one-vs-rest, максимальное допустимоей количество итераций — 2000\r\n",
        "-метод ближайшего соседа со стандартными параметрами\r\n",
        "случайный лес из 300 экстремальных деревьев\r\n",
        "-AdaBoost со стандартными параметрами\r\n",
        "\r\n",
        "Как мета-алгоритм используйте логистическую регрессию без регуляризации со схемой работы мультиклассовой классификации — auto и солвером 'lbfgs'.\r\n",
        "Посчитайте качество при помощи передачи новых признаков в функцию compute_metric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbFy38_0JQqK",
        "outputId": "7eb081b3-8499-4025-ba05-d88d50463e2f"
      },
      "source": [
        "stacked_features_train, stacked_features_test = generate_meta_features([\r\n",
        "    LogisticRegression(C=0.001, penalty='l1', solver='saga', max_iter=2000,multi_class='ovr',random_state=42),                                                                    \r\n",
        "    KNeighborsClassifier(),\r\n",
        "    ExtraTreesClassifier(n_estimators=300, n_jobs=-1,random_state=42),\r\n",
        "    AdaBoostClassifier(random_state=42)\r\n",
        "], X_train, X_test, y_train, cv)\r\n",
        "\r\n",
        "np.random.seed(42)\r\n",
        "clf = LogisticRegression(penalty='none', solver='lbfgs',multi_class='auto',random_state=42)\r\n",
        "clf.fit(stacked_features_train, y_train)\r\n",
        "\r\n",
        "compute_metric(clf, X_train=stacked_features_train, y_train=y_train, X_test=stacked_features_test,y_test=y_test)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 25%|██▌       | 1/4 [00:44<02:12, 44.05s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 50%|█████     | 2/4 [00:44<01:01, 30.95s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 75%|███████▌  | 3/4 [00:53<00:24, 24.38s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "100%|██████████| 4/4 [00:55<00:00, 13.98s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.987404"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_W07_AAYLf0D"
      },
      "source": [
        "Используйте функцию generate_meta_features для стекинга следующих алгоритмов:\r\n",
        "- случайный лес из 300 деревьев\r\n",
        "- случайный лес из 300 экстремальных деревьев\r\n",
        "\r\n",
        "Для генерации фолдов используйте класс StratifiedKFold, который позволяет делать так называемые стратифицированные разбиения (в каждом фолде будет одинаковое соотношение классов).\r\n",
        "\r\n",
        "Для корректной работы необходимо подправить код в функции compute_meta_feature. Как мета-алгоритм используйте логистическую регрессию без регуляризации со схемой работы мультиклассовой классификации — auto и солвером 'lbfgs'.\r\n",
        "Посчитайте качество при помощи передачи новых признаков в функцию compute_metric. Количество фолдов = 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKWyq77iLM5b",
        "outputId": "c4510b76-574a-4047-a7a1-a14160700019"
      },
      "source": [
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\r\n",
        "\r\n",
        "def compute_meta_feature(clf, X_train, X_test, y_train, cv):\r\n",
        "    \r\n",
        "    n_classes = len(np.unique(y_train))\r\n",
        "    X_meta_train = np.zeros((len(y_train), n_classes), dtype=np.float32)\r\n",
        "\r\n",
        "    splits = cv.split(X_train, y_train)\r\n",
        "    for train_fold_index, predict_fold_index in splits:\r\n",
        "        X_fold_train, X_fold_predict = X_train[train_fold_index], X_train[predict_fold_index]\r\n",
        "        y_fold_train = y_train[train_fold_index]\r\n",
        "        \r\n",
        "        folded_clf = clone(clf)\r\n",
        "        folded_clf.fit(X_fold_train, y_fold_train)\r\n",
        "        \r\n",
        "        X_meta_train[predict_fold_index] = folded_clf.predict_proba(X_fold_predict)\r\n",
        "    \r\n",
        "    meta_clf = clone(clf)\r\n",
        "    meta_clf.fit(X_train, y_train)\r\n",
        "    \r\n",
        "    X_meta_test = meta_clf.predict_proba(X_test)\r\n",
        "    \r\n",
        "    return X_meta_train, X_meta_test\r\n",
        "\r\n",
        "stacked_features_train, stacked_features_test = generate_meta_features([\r\n",
        "    RandomForestClassifier(n_estimators=300, n_jobs=-1,random_state=42),\r\n",
        "    ExtraTreesClassifier(n_estimators=300, n_jobs=-1,random_state=42)\r\n",
        "], X_train, X_test, y_train, cv)\r\n",
        "\r\n",
        "np.random.seed(42)\r\n",
        "# clf = LogisticRegression(penalty='none', solver='lbfgs',multi_class='auto',random_state=42)\r\n",
        "# clf = RandomForestClassifier(random_state=42)\r\n",
        "# clf = KNeighborsClassifier()\r\n",
        "clf = GradientBoostingClassifier(random_state=42)\r\n",
        "clf.fit(stacked_features_train, y_train)\r\n",
        "\r\n",
        "compute_metric(clf, X_train=stacked_features_train, y_train=y_train, X_test=stacked_features_test,y_test=y_test)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 50%|█████     | 1/2 [00:06<00:06,  6.24s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "100%|██████████| 2/2 [00:11<00:00,  5.57s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.987407"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uImDVHuDNvy0"
      },
      "source": [
        "Используйте функцию generate_meta_features для стекинга следующих алгоритмов:\r\n",
        "- случайный лес из 300 деревьев, критерий Джини, максимальная глубина — 24\r\n",
        "- случайный лес из 300 экстремальных деревьев\r\n",
        "\r\n",
        "Для генерации фолдов используйте класс StratifiedKFold, который позволяет делать так называемые стратифицированные разбиения (в каждом фолде будет одинаковое соотношение классов).\r\n",
        "Выполните разбиение на 3 фолда.\r\n",
        "Как мета-алгортм используйте случайный лес из 100 экстремальных деревьев. Посчитайте качество при помощи передачи новых признаков в функцию compute_metric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rgmin2vIL18O",
        "outputId": "3f0d74b6-6674-42f2-ff00-4dab524e6f5e"
      },
      "source": [
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\r\n",
        "\r\n",
        "stacked_features_train, stacked_features_test = generate_meta_features([\r\n",
        "    RandomForestClassifier(n_estimators=300,criterion='gini', n_jobs=-1,random_state=42),\r\n",
        "    ExtraTreesClassifier(n_estimators=300, n_jobs=-1,random_state=42)\r\n",
        "], X_train, X_test, y_train, cv)\r\n",
        "\r\n",
        "np.random.seed(42)\r\n",
        "clf = ExtraTreesClassifier(random_state=42,n_estimators=100)\r\n",
        "clf.fit(stacked_features_train, y_train)\r\n",
        "\r\n",
        "compute_metric(clf, X_train=stacked_features_train, y_train=y_train, X_test=stacked_features_test,y_test=y_test)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 50%|█████     | 1/2 [00:04<00:04,  4.08s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "100%|██████████| 2/2 [00:07<00:00,  3.57s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.986498"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8kNqtyMO2RX"
      },
      "source": [
        "Обучите на тренировочной выборке следующие алгоритмы:\r\n",
        "\r\n",
        "- случайный лес из 300 деревьев, критерий Джини, максимальная глубина — 24\r\n",
        "- случайный лес из 300 экстремальных деревьев\r\n",
        "- логистическую регрессию со стандартными параметрами\r\n",
        "\r\n",
        "Усредните их ответы на тестовой выборке и посчитайте качество аналогично функции compute_metric (F1-score с макро-усреднением, округленный до 6 знака)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSN88vLGW11K",
        "outputId": "638b051a-1b68-494d-b0cd-6f46d96998b9"
      },
      "source": [
        "algo_list = [\r\n",
        "    RandomForestClassifier(n_estimators=300,criterion='gini', n_jobs=-1,random_state=42,max_depth=24),\r\n",
        "    ExtraTreesClassifier(n_estimators=300, n_jobs=-1,random_state=42),\r\n",
        "    LogisticRegression(random_state=42)]\r\n",
        "\r\n",
        "\r\n",
        "summ = np.zeros(X_test.shape[0])\r\n",
        "\r\n",
        "for clf in algo_list:\r\n",
        "  clf.fit(X_train, y_train)\r\n",
        "  summ+= clf.predict(X_test)\r\n",
        "summ = np.floor(summ/3)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "print(summ.shape)\r\n",
        "f1_score(y_test, summ, average='macro')"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(360,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9655686924247341"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    }
  ]
}